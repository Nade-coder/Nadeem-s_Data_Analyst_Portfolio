# [PORTFOLIO PROJECTS](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/tree/main)

## 1. **Data Analysis Internship (@Psyliq)**
  - [SQL - Diabetes Prediction](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/tree/main/Data%20Analyst%20-%20Internship%20(Psyliq)/SQL%20-%20Diabetes%20Prediction)

    In the Disbetes Prediction assessment, I worked on a diabetes prediction project where I utilized SQL queries in MySQL. I successfully retrieved 
    patient IDs, calculated the average BMI of patients, and listed them in descending order of blood glucose levels. I also determined the number of patients with heart disease
    and grouped them by their smoking history. Furthermore, I updated the smoking history of patients who are older than 50 to “Ex-smoker” and inserted a new patient into the database. Lastly, I 
    found patients who have hypertension but not diabetes using the EXCEPT operator and more.
    
  ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Data%20Analyst%20-%20Internship%20(Psyliq)/SQL%20-%20Diabetes%20Prediction/sql.png?raw=true) 
    
  - [Excel - Employee Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/tree/main/Data%20Analyst%20-%20Internship%20(Psyliq)/Excel%20-%20Employee%20Data%20Analysis)
    
    In the Employee Data Analysis assessment, I was tasked with a series of Employee Data Analytics Assessment Questions. I utilized Excel to perform various tasks such as creating pivot tables to summarize the total number of employees in each department, applying conditional formatting to highlight employees with a “Performance Score” below 3, and performing advanced analysis using charts and pivot tables. I also calculated metrics including headcount, departmental budgets, training costs projections, and profitability. Developed a dashboard that provides an overview of key HR metrics, including headcount, performance, and training costs, using charts and pivot tables. This experience allowed me to enhance my Excel 
skills and gain hands-on experience in data analytics.

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Data%20Analyst%20-%20Internship%20(Psyliq)/Excel%20-%20Employee%20Data%20Analysis/HR%20analytics%20dashboard.png?raw=true)

  - [Excel and Power BI - HR Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/tree/main/Data%20Analyst%20-%20Internship%20(Psyliq)/Excel%20%26%20Power%20BI%20-%20HR%20Data%20Analysis)

    In the HR Data Analysis assessment, I tackled a series of HR Data Analytics Assessment Questions. I leveraged Excel and Power BI to execute tasks such as establishing relationship between tables, applying conditional formatting, and conducting advanced analysis using charts and pivot tables, calculating the rolling 3-month average of Monthly Income for each employee, created a hierarchy in Power BI that allows users to drill down from Department to Job Role to further narrow their analysis, set up parameterized queries in Power BI to allow users to filter data based
on the Distance from Home column. This experience enabled me to enhance my Excel and Power BI skills and gain practical experience in data analytics.

  ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Data%20Analyst%20-%20Internship%20(Psyliq)/Excel%20&%20Power%20BI%20-%20HR%20Data%20Analysis/data%20model.png?raw=true)


## 2. **Python Projects**
  - ### [Project 1 - Hotel Bookings](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%201%20-%20Hotel%20Bookings/Hotel%20Bookings.ipynb)
    
      ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%201%20-%20Hotel%20Bookings/monthly%20reservation%20status.png?raw=true)
    
      - **Project Overview**:
        In this project, I analyzed a dataset where City Hotel and Resort Hotel have seen high cancellation rates. Each hotel is dealing with a number of issues as a result, including fewer                 revenues and less than ideal hotel room use. Consequently, lowering cancellation rates is both hotels' primary goal in order to increase their efficiency in generating revenue, and for us           to offer thorough business advice to address this problem..
      -  **Data Collection**:
        The dataset was obtained from Kaggle, which included information about hotel bookings, calcellations, average daily rate and more.
      - **Data Cleaning**:
        I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
      - **Descriptive and Exploratory Data Analysis**:
        I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
      - **Findings**:
        1. We found that for city hotels, high adr leads to higher cancellations and Longer lead time are leading to more cancellations in resort hotels.
        2. Portugal has the highest number of cancellations.
        3. 47% booking from online medium.
        and more.

  - [Project 2 - Amazon Products Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%202%20-%20Amazon%20Products%20Analysis/Amazon%20Products%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%202%20-%20Amazon%20Products%20Analysis/top%20manufacturers.png?raw=true)

      - **Project Overview**: In this project, I analysed a dataset of Amazon products to help any individuals/businesses  to take business decisions by answerings various questions like - Which 
         are the top 10 products with the highest price? Which are the most popular manufacturers? The ratings of the top 10 manufacturers? and more.
      - **Data Collection**:
        The dataset was obtained from Kaggle, which included information about name, main category, sub category, actual price, discount price.
      - **Data Cleaning**:
        I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
      - **Descriptive and Exploratory Data Analysis**:
        I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
      - **Findings**:
        - The most popular manufacturers on Amazon are : Puma, Amazon, THE etc. 
        - The ratings of the Top 10 Manufacturers is usually between 4 and 5.
        - Amazon has about 5000 reviews the rest of the manufacturers' products have less than 1000 reviews.
        - Majority of popular product prices are below ₹3000.
        and more.
          
  - [Project 3 - Pharmaceutical Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%203%20-%20Pharmaceutical%20Data%20Analysis/Pharmaceutical%20Data%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%203%20-%20Pharmaceutical%20Data%20Analysis/avg%20price%20manufacturers.png?raw=true)

       - **Project Overview**: In this project, I analysed a dataset which contains all possible medicines in the Indian Pharmaceutical Industry to help any company to take business decisions by            answerings various questions like - Which manufacturer has the most products? What is the average price of the top manufacturers' products? How many products have been discontinued?
         What is the range of prices for top manufacturer? and more.
       - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about name, price, Is_discontinued, manufacturer_name, type, pack_size_label etc.
       - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
       - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
       - **Findings**:
         1. The Manufacturers' with the most products -
          - Sun Pharmaceutical Industries Ltd - 2986
          - Cipla Ltd - 2467
          - Intas Pharmaceuticals Ltd - 2302
         2. The average price of top manufacturers -
          - Sun Pharmaceutical Industries Ltd - 2986
          - Cipla Ltd - 2467
          - Intas Pharmaceuticals Ltd - 2302
         3. 7905 i.e 3.11% products have been discontinued.
         4. The range pf price of top Manufacturers -
          - Abbott min - 1.63, max - 53888.0
          - Alkem Laboratories Ltd - min - 2.05, max - 59400.0
          - Cipla Ltd - min - 1.25, max - 119500.0
          and more.
    
  - [Project 4 - Uber Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%204%20-%20Uber%20Data%20Analysis/Uber%20Data%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%204%20-%20Uber%20Data%20Analysis/rides%20per%20day.png?raw=true)

    - **Project Overview**: In this project, I analysed a dataset of world's largest taxi company Uber inc. The objective of this project is to understand Ride Patterns, identify Popular 
         Categories, temporal analysis and more.
        user Segmentation and uncover challenges and opportunities.
    - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about start date, end date, category, miles, purpose etc.
    - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
    - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
    - **Findings**:
         1. Temporal Patterns:
            - Peak Month: August and December are the peak months
            - Peak Day: Most rides are taken on Fridays, indicating higher usage towards the end of the workweek.
            - Peak Hour: The busiest time for rides is between 13 and 18 PM, possibly aligning with lunch breaks or midday activities.
        2. Ride Duration:
           The majority of ride durations fall within the 0 to 40-minute range, indicating relatively short trips.
        3. Ride Categories:
            Business rides significantly outnumber personal rides, highlighting the professional nature of the service.
        4. Purpose of Rides:
            The most common purposes for rides are meetings, followed by meal/entertainment, errands/supplies, and customer visits.
        5. Distance and Duration:
           Most rides cover distances between 0 and 50 miles, typically taking 0 to 75 minutes.
         and more.

  - [Project 5 - Paytm Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%205%20-%20Paytm%20Data%20Analysis/Paytm%20Data%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%205%20-%20Paytm%20Data%20Analysis/transaction%20vs%20loan.png?raw=true)

    - **Project Overview**: In this project, I analysed a dataset of Paytm, a leading financial technology company based in India. The objective of this project is to understand the financial             performance and trends of a business by examining key metrics such as merchandise transactions, loan volumes, revenues, and payment processing fees.
    - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about Gross Merchandise Value, Merchant Transactions, Total Transaction, Average Monthly Transacting Users, Registered              Merchants, Payment Devices etc
    - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
    - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
    - **Findings**:
         1. There is a gradual increase in the Gross Merchandise Value over every quarter.
         2. A correlation between merchant transactions Vs merchant loan volume of 0.93 indicates a very strong positive linear relationship between two variables. It suggests that when the                   transaction volume for a merchant increases, the loan volume for the merchant also tends to increase, and vice versa.
         3. Trend: The red line, merchant loan volume increases from 01-06-2020 to 01-12-2020, then there is a decline from 01-12-2020 to 01-06-2021. From 01-06-2021 there is consistent increase 
            of merchant loan volume overall.
         4. The Quarter 01-03-2023 generated the highest total revenue.
         5.  quarter 01-09-2022 generated the highest revenue from comsumers.
         and more.
    
  - [Project 6 - Zomato Bangalore Restaurants Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%206%20-%20Zomato%20Bangalore%20Restaurants%20Data%20Analysis/Zomato%20Data%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%206%20-%20Zomato%20Bangalore%20Restaurants%20Data%20Analysis/delivery%20rating.png?raw=true)

    - **Project Overview**: In this project, I analysed a dataset of Zomato, an Indian multinational company who has revolutionized the food and dining landscape globally. The objective of this           analysis is to understand the restaurant landscape in Bangalore by examining key factors such as home delivery, seating facilities, ratings, costs, popular cuisines, number of outlets, and         location.
    - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about Name, Cuisines, Area, Timing, Contact number, Is home delivery available?	Is takeaway available?
         Is indoor seating available?	Does it serve only vegetarian food? Restaurant Ratings, Restaurant Reviews etc.
    - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
    - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
    - **Findings**:
         1. 99% of restaurants in Bangalore do food delivery.
         2. 46.92% of restaurants in Bangalore have seating facility where 53.08% don't.
         3. Most common rating received by restaurants is 4.0.
         4. There is a positive correlation of 0.059 of average cost with restaurant rating, but it's very weak. There may seem to be a slight increase of average cost w.r.t ratings but nothing 
            significant.
         and more.   
    
  - [Project 7 - Netflix Data Analysis](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%207%20-%20Netflix%20Dataset%20Analysis/Netflix%20Dataset%20Analysis.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%207%20-%20Netflix%20Dataset%20Analysis/Netflix%20top%20countries.png?raw=true)

    - **Project Overview**: In this project, I analysed a dataset of Netflix, an American subscription-based streaming service that allows members to watch TV shows and movies on an internet- 
       connected device. The objective of this project is to understand the distribution and trends of content on Netflix, including the number of movies vs TV shows, premiere years, countries of 
       origin, ratings, genres, and contributions by directors.
    - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about Type of content whether TV-Show or Movie, title, director, cast, Country of release, date_added,
         release_year, rating etc.
    - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
    - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
    - **Findings**:
         1. The Number of Movies is quite high as compared to TV Shows.
         2. The highest number of Movies premiered in 2019 is 1424 and TV Shows in 2020 is 594.
         3. The highest number of shows are from USA, followed by India.
         4. Most of the Content in Netflix is rated TV-MA.
         5. Genre Drama is the highest premiered genre.
         6. Director Rajiv Chilaka is the most contributed director.
          and more.
    
  - [Project 8 - Cricket World Cup Batting 2023](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_portfolio/blob/main/Python%20Projects/Project%208%20-%20Cricket%20WC%20Batting%202023/Cricket%20WC%20Batting%202023.ipynb)

    ![](https://github.com/Nade-coder/Nadeem-s_Data_Analyst_Portfolio/blob/main/Python%20Projects/Project%208%20-%20Cricket%20WC%20Batting%202023/highest%20runs.png?raw=true)

    - **Project Overview**: In this project, I analysed a dataset of The 2023 ICC Men's Cricket World Cup. The objective of this analysis is to understand the performance of cricket players based 
        on various metrics such as runs, balls faced, 4s, 6s, dismissal types, and playing time. 
    - **Data Collection**:
         The dataset was obtained from Kaggle, which included information about player name, dismissal, runs, balls, minutes played, 4s, 6s, strike_rate etc.    
    - **Data Cleaning**:
         I preprocessed the data by handling missing values, removing duplicates, and converting data types. I used Pandas for these operations.
    - **Descriptive and Exploratory Data Analysis**:
         I performed descriptive and exploratory data analysis using Matplotlib and Seaborn.
    - **Findings**:
         1. Glenn Maxwell has scored the highest number of runs, around 200. On the other hand, Mohammad Rizwan has scored around 130 runs.
         2. The ranking of the players of most 4s and 6s is exactly the same as the ranking of the players with highest runs.
         3. A correlation of 0.93 between runs and balls in cricket indicates a strong positive relationship. This means that as the number of balls faced by a player increases, the number of runs 
            scored also tends to increase.
         4. The graph shows the distribution of average runs across different types of dismissals. The ‘c’ dismissal type i.e Caught Out has the highest average runs, while the ‘st’ dismissal type 
            i.e Stumped has the lowest.
         and more.   
    
